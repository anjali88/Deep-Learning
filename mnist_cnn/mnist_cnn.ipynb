{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_cnn",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Yl0XGVpPg2gn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Convolutional Neural Network on MNIST</h1>\n",
        "\n",
        "<h2><b>What are we talking about?</b></h2>\n",
        "<p>Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.</p>\n",
        "<p>They have applications in image and video recognition, recommender systems and natural language processing.</p>\n",
        "<h2><b>Architecture of a CNN</b></h2>\n",
        "<img src=\"img/cnn.png\" width=\"600\" height=\"400\"></img>\n",
        "\n",
        "<h3><i>Convolutional layers</i></h3>\n",
        "<p>Convolutional layers apply a convolution operation to the input, passing the result to the next layer.\n",
        "The convolution emulates the response of an individual neuron to visual stimuli.</p>\n",
        "\n",
        "<h3><i>Pooling layers</i></h3>\n",
        "<p>They combine the outputs of neuron clusters at one layer into a single neuron in the next layer.</p>\n",
        "<p>Examples: <b>max pooling</b> and <b>avg pooling</b></p>\n",
        "\n",
        "<h2>References and more infos: </h2>\n",
        "<ul>\n",
        "    <li><a href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network\">Wiki</a></li>\n",
        "    <li><a href=https://deeplearning4j.org/convolutionalnetwork>More infos</a></li>\n",
        "</ul>\n"
      ]
    },
    {
      "metadata": {
        "id": "IClCNX8_uqXD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BMSZnrwZe0cW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "height = 28\n",
        "width = 28\n",
        "channels = 1\n",
        "n_inputs = height * width\n",
        "\n",
        "# Feature maps --> a layer full of neurons using the same filters\n",
        "# Kernels --> filter's variables\n",
        "# Stride --> the distance between two consecutive receptive fields\n",
        "# Padding --> VALID if the convolutional layer does not use zero padding, SAME if uses zero padding if necessary\n",
        "conv1_fmaps = 32\n",
        "conv1_ksize = 3\n",
        "conv1_stride = 1\n",
        "conv1_pad = \"SAME\"\n",
        "\n",
        "conv2_fmaps = 64\n",
        "conv2_ksize = 3\n",
        "conv2_stride = 2\n",
        "conv2_pad = \"SAME\"\n",
        "\n",
        "pool3_fmaps = conv2_fmaps\n",
        "\n",
        "n_fc1 = 128\n",
        "\n",
        "conv2_dropout_rate = 0.25\n",
        "fc1_dropout_rate = 0.5\n",
        "\n",
        "n_outputs = 10\n",
        "\n",
        "with tf.name_scope(\"inputs\"):\n",
        "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
        "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
        "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
        "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
        "\n",
        "# First convolutional layer\n",
        "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
        "                         strides=conv1_stride, padding=conv1_pad,\n",
        "                         activation=tf.nn.relu, name=\"conv1\")\n",
        "\n",
        "# Second convolutional layer\n",
        "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
        "                         strides=conv2_stride, padding=conv2_pad,\n",
        "                         activation=tf.nn.relu, name=\"conv2\")\n",
        "\n",
        "# Pooling: subsample the image to reduce the computational load\n",
        "with tf.name_scope(\"pool3\"):\n",
        "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 7 * 7])\n",
        "    pool3_flat_drop = tf.layers.dropout(pool3_flat, conv2_dropout_rate, training=training)\n",
        "\n",
        "# Fully connected layer\n",
        "with tf.name_scope(\"fc1\"):\n",
        "    fc1 = tf.layers.dense(pool3_flat_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
        "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
        "\n",
        "with tf.name_scope(\"output\"):\n",
        "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
        "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
        "    loss = tf.reduce_mean(xentropy)\n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    training_op = optimizer.minimize(loss)\n",
        "\n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "with tf.name_scope(\"init_and_save\"):\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YOeh5wkZe5Ab",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets(\"/tmp/data/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kqMuhwlAe7GQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_model_params():\n",
        "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
        "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
        "\n",
        "def restore_model_params(model_params):\n",
        "    gvar_names = list(model_params.keys())\n",
        "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
        "                  for gvar_name in gvar_names}\n",
        "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
        "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
        "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fyf9K7TxfAsa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "143d5cb8-0394-4e4e-bc1d-27c9efe1e71d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525728254581,
          "user_tz": -120,
          "elapsed": 86935,
          "user": {
            "displayName": "Mattia Mancassola",
            "photoUrl": "//lh3.googleusercontent.com/-lyRwyRCbSzY/AAAAAAAAAAI/AAAAAAAAUYQ/zHzRCLhMZRs/s50-c-k-no/photo.jpg",
            "userId": "116324510352588137280"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 500\n",
        "batch_size = 50\n",
        "\n",
        "best_loss_val = np.infty\n",
        "check_interval = 500\n",
        "checks_since_last_progress = 0\n",
        "max_checks_without_progress = 20\n",
        "best_model_params = None \n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
        "            if iteration % check_interval == 0:\n",
        "                loss_val = loss.eval(feed_dict={X: mnist.validation.images,\n",
        "                                                y: mnist.validation.labels})\n",
        "                if loss_val < best_loss_val:\n",
        "                    best_loss_val = loss_val\n",
        "                    checks_since_last_progress = 0\n",
        "                    best_model_params = get_model_params()\n",
        "                else:\n",
        "                    checks_since_last_progress += 1\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,\n",
        "                                           y: mnist.validation.labels})\n",
        "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
        "                  epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
        "        if checks_since_last_progress > max_checks_without_progress:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "    if best_model_params:\n",
        "        restore_model_params(best_model_params)\n",
        "    acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
        "                                        y: mnist.test.labels})\n",
        "    print(\"Final accuracy on test set:\", acc_test)\n",
        "    save_path = saver.save(sess, \"./my_mnist_model\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, train accuracy: 100.0000%, valid. accuracy: 98.1600%, valid. best loss: 0.061918\n",
            "Epoch 1, train accuracy: 100.0000%, valid. accuracy: 98.8400%, valid. best loss: 0.046071\n",
            "Epoch 2, train accuracy: 100.0000%, valid. accuracy: 98.9800%, valid. best loss: 0.039397\n",
            "Epoch 3, train accuracy: 100.0000%, valid. accuracy: 99.1600%, valid. best loss: 0.036479\n",
            "Epoch 4, train accuracy: 100.0000%, valid. accuracy: 99.0000%, valid. best loss: 0.032411\n",
            "Epoch 5, train accuracy: 100.0000%, valid. accuracy: 99.0600%, valid. best loss: 0.031912\n",
            "Epoch 6, train accuracy: 100.0000%, valid. accuracy: 99.0400%, valid. best loss: 0.031912\n",
            "Epoch 7, train accuracy: 100.0000%, valid. accuracy: 98.9000%, valid. best loss: 0.031912\n",
            "Epoch 8, train accuracy: 100.0000%, valid. accuracy: 98.9400%, valid. best loss: 0.031912\n",
            "Epoch 9, train accuracy: 100.0000%, valid. accuracy: 99.0800%, valid. best loss: 0.031912\n",
            "Epoch 10, train accuracy: 100.0000%, valid. accuracy: 99.1200%, valid. best loss: 0.031912\n",
            "Epoch 11, train accuracy: 100.0000%, valid. accuracy: 99.0800%, valid. best loss: 0.031912\n",
            "Epoch 12, train accuracy: 100.0000%, valid. accuracy: 99.0800%, valid. best loss: 0.031912\n",
            "Early stopping!\n",
            "Final accuracy on test set: 0.9891\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}